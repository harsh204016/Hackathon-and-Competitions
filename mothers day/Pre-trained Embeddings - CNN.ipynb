{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "#tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3235 entries, 0 to 3234\n",
      "Data columns (total 6 columns):\n",
      "id                 3235 non-null float64\n",
      "original_text      3235 non-null object\n",
      "lang               3231 non-null object\n",
      "retweet_count      3231 non-null object\n",
      "original_author    3235 non-null object\n",
      "sentiment_class    3235 non-null int64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 151.7+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('dataset/train.csv')\n",
    "#dataset['sentiment'] = [1 if record == 'positive' else 0 for record in dataset['sentiment']]\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>sentiment_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Happy #MothersDay to all you amazing mothers o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy Mothers Day Mum - I'm sorry I can't be t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Happy mothers day To all This doing a mothers ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy mothers day to this beautiful woman...ro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remembering the 3 most amazing ladies who made...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  sentiment_class\n",
       "0  Happy #MothersDay to all you amazing mothers o...                0\n",
       "1  Happy Mothers Day Mum - I'm sorry I can't be t...                0\n",
       "2  Happy mothers day To all This doing a mothers ...               -1\n",
       "3  Happy mothers day to this beautiful woman...ro...                0\n",
       "4  Remembering the 3 most amazing ladies who made...               -1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop(['id','lang','retweet_count','original_author'],axis=1,inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500,), (500,), (2235,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = dataset['original_text'].values\n",
    "sentiments = dataset['sentiment_class'].values\n",
    "\n",
    "train_reviews = tweet[:500]\n",
    "val_reviews = tweet[500:1000]\n",
    "test_reviews = tweet[1000:]\n",
    "\n",
    "\n",
    "\n",
    "train_sentiments = sentiments[:500]\n",
    "val_sentiments = sentiments [500:1000]\n",
    "test_sentiments = sentiments[1000:]\n",
    "\n",
    "train_reviews.shape, val_reviews.shape, test_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\dell\\miniconda3\\lib\\site-packages (0.0.24)\n",
      "Requirement already satisfied: textsearch in c:\\users\\dell\\miniconda3\\lib\\site-packages (from contractions) (0.0.17)\n",
      "Requirement already satisfied: Unidecode in c:\\users\\dell\\miniconda3\\lib\\site-packages (from textsearch->contractions) (1.1.1)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\dell\\miniconda3\\lib\\site-packages (from textsearch->contractions) (1.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\dell\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textsearch in c:\\users\\dell\\miniconda3\\lib\\site-packages (0.0.17)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\dell\\miniconda3\\lib\\site-packages (from textsearch) (1.4.0)\n",
      "Requirement already satisfied: Unidecode in c:\\users\\dell\\miniconda3\\lib\\site-packages (from textsearch) (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\dell\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\dell\\miniconda3\\lib\\site-packages (4.35.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\dell\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\dell\\miniconda3\\lib\\site-packages (3.4)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\miniconda3\\lib\\site-packages (from nltk) (1.12.0)\n",
      "Requirement already satisfied: singledispatch in c:\\users\\dell\\miniconda3\\lib\\site-packages (from nltk) (3.4.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\dell\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\miniconda3\\lib\\site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\dell\\miniconda3\\lib\\site-packages (from beautifulsoup4) (1.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.0.2; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\dell\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip3 install contractions\n",
    "!pip3 install textsearch\n",
    "!pip3 install tqdm\n",
    "!pip3 install nltk\n",
    "!pip3 install beautifulsoup4\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "import tqdm\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    [s.extract() for s in soup(['iframe', 'script'])]\n",
    "    stripped_text = soup.get_text()\n",
    "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "    return stripped_text\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "def pre_process_corpus(docs):\n",
    "    norm_docs = []\n",
    "    for doc in tqdm.tqdm(docs):\n",
    "        doc = strip_html_tags(doc)\n",
    "        doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "        doc = doc.lower()\n",
    "        doc = remove_accented_chars(doc)\n",
    "        doc = contractions.fix(doc)\n",
    "        # lower case and remove special characters\\whitespaces\n",
    "        doc = re.sub(r'[^a-zA-Z0-9\\s]', ' ', doc, re.I|re.A)\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        doc = doc.strip()  \n",
    "        norm_docs.append(doc)\n",
    "    return norm_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 1318.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 3160.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2235/2235 [00:00<00:00, 3590.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "norm_train_texts = pre_process_corpus(train_reviews)\n",
    "norm_val_texts = pre_process_corpus(val_reviews)\n",
    "norm_test_texts = pre_process_corpus(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.keras.preprocessing.text.Tokenizer(oov_token='<UNK>')\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(norm_train_texts)\n",
    "t.word_index['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('vlsouxmsuq', 3700) ('<PAD>', 0) 1\n"
     ]
    }
   ],
   "source": [
    "print(max([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), \n",
    "      min([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), \n",
    "      t.word_index['<UNK>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = t.texts_to_sequences(norm_train_texts)\n",
    "val_sequences = t.texts_to_sequences(norm_val_texts)\n",
    "test_sequences = t.texts_to_sequences(norm_test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size=3701\n",
      "Number of Documents=500\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
    "print(\"Number of Documents={}\".format(t.document_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist([len(doc.split()) for doc in norm_train_texts], bins=30);\n",
    "plt.xlim([0, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 500), (2235, 500))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "\n",
    "# pad dataset to a maximum review length in words\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_val = tf.keras.preprocessing.sequence.pad_sequences(val_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(t.word_index)\n",
    "EMBED_SIZE = 300\n",
    "EPOCHS=100\n",
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = t.word_index\n",
    "FASTTEXT_INIT_EMBEDDINGS_FILE = 'wiki-news-300d-1M-subword.vec'\n",
    "\n",
    "\n",
    "def load_pretrained_embeddings(word_to_index, max_features, embedding_size, embedding_file_path):    \n",
    "    \n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    embeddings_index = dict(get_coefs(*row.split(\" \")) \n",
    "                                for row in open(embedding_file_path, encoding=\"utf8\", errors='ignore') \n",
    "                                    if len(row)>100)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    nb_words = min(max_features, len(word_to_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embedding_size))\n",
    "    \n",
    "    for word, idx in word_to_index.items():\n",
    "        if idx >= max_features: \n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[idx] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3701, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_embeddings = load_pretrained_embeddings(word_to_index=word2idx, \n",
    "                                           max_features=VOCAB_SIZE, \n",
    "                                           embedding_size=EMBED_SIZE, \n",
    "                                           embedding_file_path=FASTTEXT_INIT_EMBEDDINGS_FILE)\n",
    "ft_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Input 'y' of 'Equal' Op has type float32 that does not match type int32 of argument 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    510\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[0;32m    512\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\u001b[0m\n\u001b[0;32m   1174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[1;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    976\u001b[0m         \u001b[1;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[0;32m    978\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"metrics/acc/Cast_6:0\", shape=(?, 1), dtype=float32)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f1024c245441>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m       \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[0;32m    497\u001b[0m           \u001b[0mtargets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m           \u001b[0mskip_target_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskip_target_indices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           sample_weights=self.sample_weights)\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m       \u001b[1;31m# Prepare gradient updates and state updates.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_handle_metrics\u001b[1;34m(self, outputs, skip_target_indices, targets, sample_weights, masks, return_stateful_result)\u001b[0m\n\u001b[0;32m   1842\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1843\u001b[0m                 \u001b[0moutput_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1844\u001b[1;33m                 return_stateful_result=return_stateful_result))\n\u001b[0m\u001b[0;32m   1845\u001b[0m         metric_results.extend(\n\u001b[0;32m   1846\u001b[0m             self._handle_per_output_metrics(\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_handle_per_output_metrics\u001b[1;34m(self, metrics_dict, y_true, y_pred, mask, weights, return_stateful_result)\u001b[0m\n\u001b[0;32m   1799\u001b[0m           \u001b[1;31m# stateless fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1800\u001b[0m           \u001b[0mstateful_metric_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstateful_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1801\u001b[1;33m           \u001b[0mmetric_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1802\u001b[0m           _track_metric_tensors(metric_name, metric_result,\n\u001b[0;32m   1803\u001b[0m                                 stateful_metric_result)\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_call_stateless_fn\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m   1775\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_call_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1776\u001b[0m           \u001b[0mweighted_metric_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweighted_masked_objective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1777\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mweighted_metric_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1779\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_track_metric_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstateless_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstateful_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[1;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[0;32m    645\u001b[0m     \"\"\"\n\u001b[0;32m    646\u001b[0m     \u001b[1;31m# score_array has ndim >= 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m     \u001b[0mscore_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m       \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mbinary_accuracy\u001b[1;34m(y_true, y_pred, threshold)\u001b[0m\n\u001b[0;32m   1531\u001b[0m   \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1533\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   3091\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3092\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 3093\u001b[1;33m         \"Equal\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   3094\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3095\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    545\u001b[0m                   \u001b[1;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[1;32m--> 547\u001b[1;33m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Input 'y' of 'Equal' Op has type float32 that does not match type int32 of argument 'x'."
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Embedding(VOCAB_SIZE, EMBED_SIZE,\n",
    "                                    weights=[ft_embeddings],\n",
    "                                    trainable=True,\n",
    "                                    input_length=MAX_SEQUENCE_LENGTH))\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(filters=256, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 12s 2ms/sample - loss: 0.6946 - accuracy: 0.4942 - val_loss: 0.6920 - val_accuracy: 0.5564\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 11s 2ms/sample - loss: 0.6516 - accuracy: 0.6012 - val_loss: 0.4277 - val_accuracy: 0.8154\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 11s 2ms/sample - loss: 0.2726 - accuracy: 0.8904 - val_loss: 0.3079 - val_accuracy: 0.8708\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 10s 2ms/sample - loss: 0.0636 - accuracy: 0.9808 - val_loss: 0.4348 - val_accuracy: 0.8630\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 10s 2ms/sample - loss: 0.0082 - accuracy: 0.9976 - val_loss: 0.6429 - val_accuracy: 0.8636\n",
      "Epoch 6/100\n",
      "4992/5000 [============================>.] - ETA: 0s - loss: 6.0563e-04 - accuracy: 0.9998Restoring model weights from the end of the best epoch.\n",
      "5000/5000 [==============================] - 10s 2ms/sample - loss: 6.0471e-04 - accuracy: 0.9998 - val_loss: 0.8038 - val_accuracy: 0.8738\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f42407826a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                      patience=3,\n",
    "                                      restore_best_weights=True,\n",
    "                                      verbose=1)\n",
    "\n",
    "model.fit(X_train, train_sentiments, \n",
    "          validation_data=(X_val, val_sentiments),\n",
    "          epochs=EPOCHS, \n",
    "          batch_size=BATCH_SIZE, \n",
    "          shuffle=True,\n",
    "          callbacks=[es],\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.40%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.91      0.87     20028\n",
      "          1       0.90      0.81      0.86     19972\n",
      "\n",
      "avg / total       0.87      0.86      0.86     40000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18293</td>\n",
       "      <td>1735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3705</td>\n",
       "      <td>16267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  18293   1735\n",
       "1   3705  16267"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "predictions = model.predict_classes(X_test, batch_size=2048, verbose=0).ravel()\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_score(test_sentiments, predictions)*100))\n",
    "print(classification_report(test_sentiments, predictions))\n",
    "pd.DataFrame(confusion_matrix(test_sentiments, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
