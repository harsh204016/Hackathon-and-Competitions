{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC ,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,train_test_split , KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 24), (3000, 23))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "train.shape , test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 24)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest = train.append(test)\n",
    "traintest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Relationship_Status</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Decision_skill_possess</th>\n",
       "      <th>Time_of_service</th>\n",
       "      <th>Time_since_promotion</th>\n",
       "      <th>...</th>\n",
       "      <th>Compensation_and_Benefits</th>\n",
       "      <th>Work_Life_balance</th>\n",
       "      <th>VAR1</th>\n",
       "      <th>VAR2</th>\n",
       "      <th>VAR3</th>\n",
       "      <th>VAR4</th>\n",
       "      <th>VAR5</th>\n",
       "      <th>VAR6</th>\n",
       "      <th>VAR7</th>\n",
       "      <th>Attrition_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EID_23371</td>\n",
       "      <td>F</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Married</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>IT</td>\n",
       "      <td>Conceptual</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>type2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>1.8688</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EID_18000</td>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Single</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>Analytical</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>type2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.9612</td>\n",
       "      <td>-0.4537</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EID_3891</td>\n",
       "      <td>F</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Married</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>Quality</td>\n",
       "      <td>Conceptual</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>type2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.9612</td>\n",
       "      <td>-0.4537</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Employee_ID Gender   Age  Education_Level Relationship_Status     Hometown  \\\n",
       "0   EID_23371      F  42.0                4             Married     Franklin   \n",
       "1   EID_18000      M  24.0                3              Single  Springfield   \n",
       "2    EID_3891      F  58.0                3             Married      Clinton   \n",
       "\n",
       "        Unit Decision_skill_possess  Time_of_service  Time_since_promotion  \\\n",
       "0         IT             Conceptual              4.0                     4   \n",
       "1  Logistics             Analytical              5.0                     4   \n",
       "2    Quality             Conceptual             27.0                     3   \n",
       "\n",
       "   ...  Compensation_and_Benefits  Work_Life_balance  VAR1    VAR2    VAR3  \\\n",
       "0  ...                      type2                3.0     4  0.7516  1.8688   \n",
       "1  ...                      type2                4.0     3 -0.9612 -0.4537   \n",
       "2  ...                      type2                1.0     4 -0.9612 -0.4537   \n",
       "\n",
       "   VAR4  VAR5  VAR6  VAR7  Attrition_rate  \n",
       "0   2.0     4     5     3          0.1841  \n",
       "1   2.0     3     5     3          0.0670  \n",
       "2   3.0     3     8     3          0.0851  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Relationship_Status</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Decision_skill_possess</th>\n",
       "      <th>Time_of_service</th>\n",
       "      <th>Time_since_promotion</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Pay_Scale</th>\n",
       "      <th>Compensation_and_Benefits</th>\n",
       "      <th>Work_Life_balance</th>\n",
       "      <th>VAR1</th>\n",
       "      <th>VAR2</th>\n",
       "      <th>VAR3</th>\n",
       "      <th>VAR4</th>\n",
       "      <th>VAR5</th>\n",
       "      <th>VAR6</th>\n",
       "      <th>VAR7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Married</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>IT</td>\n",
       "      <td>Conceptual</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>type2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>1.8688</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Single</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>Logistics</td>\n",
       "      <td>Analytical</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>type2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.9612</td>\n",
       "      <td>-0.4537</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Married</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>Quality</td>\n",
       "      <td>Conceptual</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>type2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.9612</td>\n",
       "      <td>-0.4537</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender   Age  Education_Level Relationship_Status     Hometown       Unit  \\\n",
       "0      F  42.0                4             Married     Franklin         IT   \n",
       "1      M  24.0                3              Single  Springfield  Logistics   \n",
       "2      F  58.0                3             Married      Clinton    Quality   \n",
       "\n",
       "  Decision_skill_possess  Time_of_service  Time_since_promotion  growth_rate  \\\n",
       "0             Conceptual              4.0                     4           33   \n",
       "1             Analytical              5.0                     4           36   \n",
       "2             Conceptual             27.0                     3           51   \n",
       "\n",
       "   ...  Pay_Scale  Compensation_and_Benefits  Work_Life_balance VAR1    VAR2  \\\n",
       "0  ...        7.0                      type2                3.0    4  0.7516   \n",
       "1  ...        6.0                      type2                4.0    3 -0.9612   \n",
       "2  ...        8.0                      type2                1.0    4 -0.9612   \n",
       "\n",
       "     VAR3  VAR4  VAR5  VAR6  VAR7  \n",
       "0  1.8688   2.0     4     5     3  \n",
       "1 -0.4537   2.0     3     5     3  \n",
       "2 -0.4537   3.0     3     8     3  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = traintest['Attrition_rate']\n",
    "traintest.drop(['Attrition_rate','Employee_ID'],axis=1,inplace=True)\n",
    "traintest.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 22), (10000,))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                        2\n",
       "Age                          48\n",
       "Education_Level               5\n",
       "Relationship_Status           2\n",
       "Hometown                      5\n",
       "Unit                         12\n",
       "Decision_skill_possess        4\n",
       "Time_of_service              45\n",
       "Time_since_promotion          5\n",
       "growth_rate                  55\n",
       "Travel_Rate                   3\n",
       "Post_Level                    5\n",
       "Pay_Scale                    11\n",
       "Compensation_and_Benefits     5\n",
       "Work_Life_balance             6\n",
       "VAR1                          5\n",
       "VAR2                          6\n",
       "VAR3                          5\n",
       "VAR4                          4\n",
       "VAR5                          5\n",
       "VAR6                          5\n",
       "VAR7                          5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.nunique(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                         0\n",
       "Age                          573\n",
       "Education_Level                0\n",
       "Relationship_Status            0\n",
       "Hometown                       0\n",
       "Unit                           0\n",
       "Decision_skill_possess         0\n",
       "Time_of_service              196\n",
       "Time_since_promotion           0\n",
       "growth_rate                    0\n",
       "Travel_Rate                    0\n",
       "Post_Level                     0\n",
       "Pay_Scale                     12\n",
       "Compensation_and_Benefits      0\n",
       "Work_Life_balance             16\n",
       "VAR1                           0\n",
       "VAR2                         794\n",
       "VAR3                           0\n",
       "VAR4                         954\n",
       "VAR5                           0\n",
       "VAR6                           0\n",
       "VAR7                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for handling missing value in AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN     573\n",
       "22.0    347\n",
       "27.0    336\n",
       "25.0    320\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.Age.value_counts(dropna=False).head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9427.000000\n",
       "mean       39.675507\n",
       "std        13.574856\n",
       "min        19.000000\n",
       "25%        27.000000\n",
       "50%        38.000000\n",
       "75%        52.000000\n",
       "max        65.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.Age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()\n",
    "#ax.scatter(x = train['Age'], y = train['Attrition_rate'])\n",
    "#plt.ylabel('Attrition_rate', fontsize=13)\n",
    "#plt.xlabel('Age', fontsize=13)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9427.000000\n",
       "mean       39.675507\n",
       "std        13.574856\n",
       "min        19.000000\n",
       "25%        27.000000\n",
       "50%        38.000000\n",
       "75%        52.000000\n",
       "max        65.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest['Age'].fillna(traintest.groupby(['Gender', 'Education_Level'])['Age'].transform('median'))\n",
    "traintest.Age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9427.000000\n",
       "mean       39.675507\n",
       "std        13.574856\n",
       "min        19.000000\n",
       "25%        27.000000\n",
       "50%        38.000000\n",
       "75%        52.000000\n",
       "max        65.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest['Age'].fillna(traintest.groupby(['Gender', 'Time_since_promotion'])['Age'].transform('median'))\n",
    "traintest.Age.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10000.000000\n",
       "mean        39.675507\n",
       "std         13.180160\n",
       "min         19.000000\n",
       "25%         28.000000\n",
       "50%         39.675507\n",
       "75%         51.000000\n",
       "max         65.000000\n",
       "Name: Age_Mean_Filled, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_imputation_df = traintest.copy()\n",
    "mean_imputation_df['Age_Mean_Filled'] = mean_imputation_df['Age'].fillna(traintest['Age'].mean())\n",
    "mean_imputation_df.Age_Mean_Filled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest['Age'].fillna(traintest.groupby(['Gender', 'Hometown'])['Age'].transform('median'),inplace=True)\n",
    "#traintest.Age.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for handling missing value in var4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    6369\n",
       "1.0    1809\n",
       "NaN     954\n",
       "3.0     868\n",
       "Name: VAR4, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.VAR4.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    6369\n",
       "1.0    1809\n",
       "4.0     954\n",
       "3.0     868\n",
       "Name: VAR4, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.VAR4.fillna(4.0,inplace=True)\n",
    "traintest.VAR4.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for handling missing value in var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.7516    3582\n",
       "-0.1048    2288\n",
       "-0.9612    1469\n",
       "-1.8176    1173\n",
       " NaN        794\n",
       " 1.6081     694\n",
       "Name: VAR2, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.VAR2.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.7516    3582\n",
       "-0.1048    2288\n",
       "-0.9612    1469\n",
       "-1.8176    1173\n",
       " 0.0000     794\n",
       " 1.6081     694\n",
       "Name: VAR2, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.VAR2.fillna(0.0,inplace=True)\n",
    "traintest.VAR2.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                         0\n",
       "Age                            0\n",
       "Education_Level                0\n",
       "Relationship_Status            0\n",
       "Hometown                       0\n",
       "Unit                           0\n",
       "Decision_skill_possess         0\n",
       "Time_of_service              196\n",
       "Time_since_promotion           0\n",
       "growth_rate                    0\n",
       "Travel_Rate                    0\n",
       "Post_Level                     0\n",
       "Pay_Scale                     12\n",
       "Compensation_and_Benefits      0\n",
       "Work_Life_balance             16\n",
       "VAR1                           0\n",
       "VAR2                           0\n",
       "VAR3                           0\n",
       "VAR4                           0\n",
       "VAR5                           0\n",
       "VAR6                           0\n",
       "VAR7                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest['Pay_Scale'].fillna(traintest.Pay_Scale.median(),inplace=True)\n",
    "traintest['Time_of_service'].fillna(traintest.Time_of_service.mean(),inplace=True)\n",
    "traintest['Work_Life_balance'].fillna(traintest.Work_Life_balance.mean(),inplace=True)\n",
    "traintest['time'] = traintest.apply(lambda row: row.Time_of_service - row.Time_since_promotion , axis = 1) \n",
    "traintest['age_while_joining'] = traintest.apply(lambda r:r.Age - r.Time_of_service,axis=1)\n",
    "traintest.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 24)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features =  list(traintest.select_dtypes(include=object).columns)\n",
    "for i in cat_features:\n",
    "    l = LabelEncoder()\n",
    "    traintest[i] = l.fit_transform(traintest[i])\n",
    "traintest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_features =  list(traintest.select_dtypes(include=object).columns)\n",
    "#traintest = pd.get_dummies(traintest,columns=cat_features,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Relationship_Status</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Decision_skill_possess</th>\n",
       "      <th>Time_of_service</th>\n",
       "      <th>Time_since_promotion</th>\n",
       "      <th>growth_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Work_Life_balance</th>\n",
       "      <th>VAR1</th>\n",
       "      <th>VAR2</th>\n",
       "      <th>VAR3</th>\n",
       "      <th>VAR4</th>\n",
       "      <th>VAR5</th>\n",
       "      <th>VAR6</th>\n",
       "      <th>VAR7</th>\n",
       "      <th>time</th>\n",
       "      <th>age_while_joining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>1.8688</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.9612</td>\n",
       "      <td>-0.4537</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.9612</td>\n",
       "      <td>-0.4537</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.8176</td>\n",
       "      <td>-0.4537</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7516</td>\n",
       "      <td>-0.4537</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Education_Level  Relationship_Status  Hometown  Unit  \\\n",
       "0       0  42.0                4                    0         1     2   \n",
       "1       1  24.0                3                    1         3     3   \n",
       "2       0  58.0                3                    0         0     8   \n",
       "3       0  26.0                3                    1         2     1   \n",
       "4       0  31.0                1                    0         3     3   \n",
       "\n",
       "   Decision_skill_possess  Time_of_service  Time_since_promotion  growth_rate  \\\n",
       "0                       2              4.0                     4           33   \n",
       "1                       0              5.0                     4           36   \n",
       "2                       2             27.0                     3           51   \n",
       "3                       1              4.0                     3           56   \n",
       "4                       2              5.0                     4           62   \n",
       "\n",
       "   ...  Work_Life_balance  VAR1    VAR2    VAR3  VAR4  VAR5  VAR6  VAR7  time  \\\n",
       "0  ...                3.0     4  0.7516  1.8688   2.0     4     5     3   0.0   \n",
       "1  ...                4.0     3 -0.9612 -0.4537   2.0     3     5     3   1.0   \n",
       "2  ...                1.0     4 -0.9612 -0.4537   3.0     3     8     3  24.0   \n",
       "3  ...                1.0     3 -1.8176 -0.4537   4.0     3     7     3   1.0   \n",
       "4  ...                3.0     1  0.7516 -0.4537   2.0     2     8     2   1.0   \n",
       "\n",
       "   age_while_joining  \n",
       "0               38.0  \n",
       "1               19.0  \n",
       "2               31.0  \n",
       "3               22.0  \n",
       "4               26.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 24)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_X=traintest.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(traintest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 24) (7000,)\n",
      "(3000, 24)\n"
     ]
    }
   ],
   "source": [
    "#X_train = X[:7000,:]\n",
    "#Y_train = y[:7000]\n",
    "#X_test = X[7000:,:]\n",
    "\n",
    "X_train = traintest.iloc[:7000,:]\n",
    "Y_train = y.iloc[:7000]\n",
    "X_test = traintest.iloc[7000:,:]\n",
    "\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [3,5, 10,25,50]\n",
    "learning_rate=[0.05,0.1,0.15,0.20,0.01]\n",
    "min_child_weight=[0,1,2,4]\n",
    "subsample =[0.5,0.75,1]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score,\n",
    "    'subsample':subsample\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed: 30.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          importance_type='gain',\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=3, min_child_weight=1,\n",
       "                                          missing=None, n_estimators=100,\n",
       "                                          n_jobs=1, nthread=None,\n",
       "                                          objective='reg:linear',\n",
       "                                          random_state=0, reg_alpha=0,\n",
       "                                          r...\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.01],\n",
       "                                        'max_depth': [5, 10, 15, 25, 50],\n",
       "                                        'min_child_weight': [0, 1, 2, 4],\n",
       "                                        'n_estimators': [100, 500, 900, 1100,\n",
       "                                                         1500],\n",
       "                                        'subsample': [0.5, 0.75, 1]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "regressor=xgb.XGBRegressor()\n",
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)\n",
    "random_cv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.5,\n",
       " 'n_estimators': 500,\n",
       " 'min_child_weight': 2,\n",
       " 'max_depth': 5,\n",
       " 'learning_rate': 0.2,\n",
       " 'booster': 'gblinear',\n",
       " 'base_score': 0.25}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:56:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gblinear', colsample_bylevel=None,\n",
       "             colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "             gpu_id=-1, importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.2, max_delta_step=None, max_depth=5,\n",
       "             min_child_weight=2, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=700, n_jobs=0, num_parallel_tree=None,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=0, scale_pos_weight=1, subsample=0.5, tree_method=None,\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbmodel = xgb.XGBRegressor(subsample= 0.5,\n",
    " n_estimators=700,\n",
    " min_child_weight= 2,\n",
    " max_depth= 5,\n",
    " learning_rate= 0.2,\n",
    " booster='gblinear',\n",
    " base_score= 0.25)\n",
    "xgbmodel.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "yxgbreg = xgbmodel.predict(X_test)\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = yxgbreg\n",
    "sub.to_csv('xgboost_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1, 5)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test = np.zeros((test.shape[0],1, 5))\n",
    "#y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:18:08] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "(3000, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can only tuple-index with a MultiIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_with_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSettingWithCopyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_set_with_engine\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.set_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.set_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-6b90ce7f6cfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1026\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can only tuple-index with a MultiIndex\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[1;31m# python 3 type errors should be raised\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Can only tuple-index with a MultiIndex"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "warnings.filterwarnings('ignore')\n",
    "scores = []\n",
    "\n",
    "i=0\n",
    "for train_index, test_index in kfold.split(X_train):   \n",
    "    x_train, x_test = X_train[train_index], X_train[test_index]\n",
    "    y_train, y_test = Y_train[train_index], Y_train[test_index]\n",
    "\n",
    "    xgb_model = xgb.XGBRegressor(subsample= 0.7,n_estimators=500,\n",
    "                                 min_child_weight= 2,max_depth= 5,\n",
    "                                 learning_rate= 0.2,booster='gblinear',\n",
    "                                 base_score= 0.25)\n",
    "    \n",
    "    xgb_model.fit(x_train, y_train)\n",
    "    y_pred = xgb_model.predict(x_test)\n",
    "    scores.append(100*max(0,1-np.sqrt(mean_squared_error(y_test,y_pred))))\n",
    "    y_test = xgb_model.predict(X_test,num_iteration = iter_)\n",
    "    xgb_model.predict()\n",
    "    \n",
    "    \n",
    "print(scores)\n",
    "print('mean',np.mean(scores))\n",
    "print('std',np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:04] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.1.0\\src\\learner.cc:480: \n",
      "Parameters: { max_depth, min_child_weight, n_estimators, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-rmse:0.18965\teval-rmse:0.20952\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[6]\ttrain-rmse:0.18326\teval-rmse:0.20611\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict() got an unexpected keyword argument 'num_iteration'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-9f84db63f5e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mscore_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mtest_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtest_preds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreds\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: predict() got an unexpected keyword argument 'num_iteration'"
     ]
    }
   ],
   "source": [
    "n_folds=10 \n",
    "seed =0\n",
    "skf = KFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "X, y = X_train, Y_train\n",
    "    \n",
    "preds = np.zeros(test.shape[0])\n",
    "    \n",
    "params={'subsample': 0.5,\n",
    " 'n_estimators': 500,\n",
    " 'min_child_weight': 2,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.2,\n",
    " 'booster': 'gblinear',\n",
    " 'base_score': 0.25}\n",
    "    \n",
    "for i, (itr, icv) in enumerate(skf.split(X, y)):\n",
    "    x_train, x_val = X[itr, :], X[icv, :]\n",
    "    y_train, y_val = y[itr], y[icv]\n",
    "\n",
    "    dtrain = xgb.DMatrix(data=x_train, label=y_train, missing=np.nan)\n",
    "    dval = xgb.DMatrix(data = x_val, label=y_val, missing=np.nan)\n",
    "\n",
    "    bst = xgb.train(\n",
    "                params                = params,\n",
    "                dtrain                = dtrain,\n",
    "                num_boost_round       = 30_000,\n",
    "                early_stopping_rounds = 200,\n",
    "                evals                 = [(dtrain, 'train'), (dval, 'eval')],\n",
    "                verbose_eval          = 500\n",
    "            )\n",
    "\n",
    "    score_, iter_ = bst.best_score, bst.best_iteration\n",
    "    bst.predict()\n",
    "    test_preds = bst.predict(xgb.DMatrix(X_train), num_iteration = iter_)\n",
    "    preds += test_preds\n",
    "preds=preds / n_folds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u=xgb_model.predict(X_test).reshape(3000,1)\n",
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u=u.reshape(3000,1)\n",
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.12549\tvalid_0's l2: 0.0348143\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l1: 0.125485\tvalid_0's l2: 0.0348165\n",
      "[3]\tvalid_0's l1: 0.125486\tvalid_0's l2: 0.0348196\n",
      "[4]\tvalid_0's l1: 0.125479\tvalid_0's l2: 0.0348214\n",
      "[5]\tvalid_0's l1: 0.125475\tvalid_0's l2: 0.0348226\n",
      "[6]\tvalid_0's l1: 0.125473\tvalid_0's l2: 0.0348234\n",
      "[7]\tvalid_0's l1: 0.125477\tvalid_0's l2: 0.0348253\n",
      "[8]\tvalid_0's l1: 0.125477\tvalid_0's l2: 0.0348254\n",
      "[9]\tvalid_0's l1: 0.125471\tvalid_0's l2: 0.0348265\n",
      "[10]\tvalid_0's l1: 0.125465\tvalid_0's l2: 0.0348282\n",
      "[11]\tvalid_0's l1: 0.125452\tvalid_0's l2: 0.0348256\n",
      "[12]\tvalid_0's l1: 0.125438\tvalid_0's l2: 0.0348207\n",
      "[13]\tvalid_0's l1: 0.12543\tvalid_0's l2: 0.034818\n",
      "[14]\tvalid_0's l1: 0.125432\tvalid_0's l2: 0.0348191\n",
      "[15]\tvalid_0's l1: 0.125417\tvalid_0's l2: 0.0348137\n",
      "[16]\tvalid_0's l1: 0.125411\tvalid_0's l2: 0.0348119\n",
      "[17]\tvalid_0's l1: 0.12541\tvalid_0's l2: 0.0348124\n",
      "[18]\tvalid_0's l1: 0.125399\tvalid_0's l2: 0.0348089\n",
      "[19]\tvalid_0's l1: 0.125396\tvalid_0's l2: 0.0348069\n",
      "[20]\tvalid_0's l1: 0.125393\tvalid_0's l2: 0.0348064\n",
      "[21]\tvalid_0's l1: 0.125385\tvalid_0's l2: 0.0348048\n",
      "[22]\tvalid_0's l1: 0.125384\tvalid_0's l2: 0.0348034\n",
      "[23]\tvalid_0's l1: 0.125378\tvalid_0's l2: 0.0348049\n",
      "[24]\tvalid_0's l1: 0.125371\tvalid_0's l2: 0.0348036\n",
      "[25]\tvalid_0's l1: 0.125362\tvalid_0's l2: 0.0348045\n",
      "[26]\tvalid_0's l1: 0.125365\tvalid_0's l2: 0.0348041\n",
      "[27]\tvalid_0's l1: 0.125359\tvalid_0's l2: 0.0348029\n",
      "[28]\tvalid_0's l1: 0.125353\tvalid_0's l2: 0.0348025\n",
      "[29]\tvalid_0's l1: 0.125349\tvalid_0's l2: 0.0348028\n",
      "[30]\tvalid_0's l1: 0.125348\tvalid_0's l2: 0.0348026\n",
      "[31]\tvalid_0's l1: 0.125349\tvalid_0's l2: 0.034801\n",
      "[32]\tvalid_0's l1: 0.125346\tvalid_0's l2: 0.0347999\n",
      "[33]\tvalid_0's l1: 0.12534\tvalid_0's l2: 0.0347972\n",
      "[34]\tvalid_0's l1: 0.125335\tvalid_0's l2: 0.034797\n",
      "[35]\tvalid_0's l1: 0.125334\tvalid_0's l2: 0.0347967\n",
      "[36]\tvalid_0's l1: 0.125339\tvalid_0's l2: 0.0347961\n",
      "[37]\tvalid_0's l1: 0.125344\tvalid_0's l2: 0.0347976\n",
      "[38]\tvalid_0's l1: 0.125349\tvalid_0's l2: 0.0347991\n",
      "[39]\tvalid_0's l1: 0.125354\tvalid_0's l2: 0.0348008\n",
      "[40]\tvalid_0's l1: 0.125362\tvalid_0's l2: 0.0348041\n",
      "[41]\tvalid_0's l1: 0.125374\tvalid_0's l2: 0.0348089\n",
      "[42]\tvalid_0's l1: 0.125384\tvalid_0's l2: 0.0348127\n",
      "[43]\tvalid_0's l1: 0.125386\tvalid_0's l2: 0.0348145\n",
      "[44]\tvalid_0's l1: 0.125402\tvalid_0's l2: 0.0348212\n",
      "[45]\tvalid_0's l1: 0.125411\tvalid_0's l2: 0.0348268\n",
      "[46]\tvalid_0's l1: 0.125418\tvalid_0's l2: 0.034832\n",
      "[47]\tvalid_0's l1: 0.12543\tvalid_0's l2: 0.0348373\n",
      "[48]\tvalid_0's l1: 0.125437\tvalid_0's l2: 0.0348366\n",
      "[49]\tvalid_0's l1: 0.125447\tvalid_0's l2: 0.0348409\n",
      "[50]\tvalid_0's l1: 0.125461\tvalid_0's l2: 0.0348472\n",
      "[51]\tvalid_0's l1: 0.125465\tvalid_0's l2: 0.0348474\n",
      "[52]\tvalid_0's l1: 0.125467\tvalid_0's l2: 0.0348474\n",
      "[53]\tvalid_0's l1: 0.125467\tvalid_0's l2: 0.0348489\n",
      "[54]\tvalid_0's l1: 0.125468\tvalid_0's l2: 0.0348493\n",
      "[55]\tvalid_0's l1: 0.125467\tvalid_0's l2: 0.0348492\n",
      "[56]\tvalid_0's l1: 0.125473\tvalid_0's l2: 0.0348512\n",
      "[57]\tvalid_0's l1: 0.12547\tvalid_0's l2: 0.0348482\n",
      "[58]\tvalid_0's l1: 0.125477\tvalid_0's l2: 0.0348511\n",
      "[59]\tvalid_0's l1: 0.125477\tvalid_0's l2: 0.0348491\n",
      "[60]\tvalid_0's l1: 0.125479\tvalid_0's l2: 0.0348514\n",
      "[61]\tvalid_0's l1: 0.125464\tvalid_0's l2: 0.0348479\n",
      "[62]\tvalid_0's l1: 0.125465\tvalid_0's l2: 0.034847\n",
      "[63]\tvalid_0's l1: 0.125469\tvalid_0's l2: 0.0348443\n",
      "[64]\tvalid_0's l1: 0.125477\tvalid_0's l2: 0.0348482\n",
      "[65]\tvalid_0's l1: 0.125475\tvalid_0's l2: 0.0348504\n",
      "[66]\tvalid_0's l1: 0.12548\tvalid_0's l2: 0.0348559\n",
      "[67]\tvalid_0's l1: 0.125481\tvalid_0's l2: 0.0348567\n",
      "[68]\tvalid_0's l1: 0.125487\tvalid_0's l2: 0.0348608\n",
      "[69]\tvalid_0's l1: 0.125489\tvalid_0's l2: 0.0348647\n",
      "[70]\tvalid_0's l1: 0.125493\tvalid_0's l2: 0.0348677\n",
      "[71]\tvalid_0's l1: 0.125498\tvalid_0's l2: 0.0348698\n",
      "[72]\tvalid_0's l1: 0.125502\tvalid_0's l2: 0.0348687\n",
      "[73]\tvalid_0's l1: 0.125506\tvalid_0's l2: 0.0348682\n",
      "[74]\tvalid_0's l1: 0.125506\tvalid_0's l2: 0.0348666\n",
      "[75]\tvalid_0's l1: 0.12551\tvalid_0's l2: 0.034866\n",
      "[76]\tvalid_0's l1: 0.1255\tvalid_0's l2: 0.0348586\n",
      "[77]\tvalid_0's l1: 0.125503\tvalid_0's l2: 0.0348581\n",
      "[78]\tvalid_0's l1: 0.125507\tvalid_0's l2: 0.0348574\n",
      "[79]\tvalid_0's l1: 0.125505\tvalid_0's l2: 0.0348559\n",
      "[80]\tvalid_0's l1: 0.125507\tvalid_0's l2: 0.0348556\n",
      "[81]\tvalid_0's l1: 0.1255\tvalid_0's l2: 0.0348527\n",
      "[82]\tvalid_0's l1: 0.125504\tvalid_0's l2: 0.0348522\n",
      "[83]\tvalid_0's l1: 0.125505\tvalid_0's l2: 0.0348505\n",
      "[84]\tvalid_0's l1: 0.1255\tvalid_0's l2: 0.034849\n",
      "[85]\tvalid_0's l1: 0.12549\tvalid_0's l2: 0.0348434\n",
      "[86]\tvalid_0's l1: 0.125494\tvalid_0's l2: 0.0348443\n",
      "[87]\tvalid_0's l1: 0.125491\tvalid_0's l2: 0.0348433\n",
      "[88]\tvalid_0's l1: 0.125501\tvalid_0's l2: 0.0348465\n",
      "[89]\tvalid_0's l1: 0.12551\tvalid_0's l2: 0.0348496\n",
      "[90]\tvalid_0's l1: 0.125506\tvalid_0's l2: 0.0348474\n",
      "[91]\tvalid_0's l1: 0.125512\tvalid_0's l2: 0.0348464\n",
      "[92]\tvalid_0's l1: 0.125517\tvalid_0's l2: 0.0348441\n",
      "[93]\tvalid_0's l1: 0.125528\tvalid_0's l2: 0.0348482\n",
      "[94]\tvalid_0's l1: 0.125545\tvalid_0's l2: 0.0348498\n",
      "[95]\tvalid_0's l1: 0.125564\tvalid_0's l2: 0.0348508\n",
      "[96]\tvalid_0's l1: 0.12558\tvalid_0's l2: 0.0348535\n",
      "[97]\tvalid_0's l1: 0.12558\tvalid_0's l2: 0.0348521\n",
      "[98]\tvalid_0's l1: 0.125582\tvalid_0's l2: 0.0348497\n",
      "[99]\tvalid_0's l1: 0.125593\tvalid_0's l2: 0.0348546\n",
      "[100]\tvalid_0's l1: 0.125593\tvalid_0's l2: 0.0348526\n",
      "[101]\tvalid_0's l1: 0.125606\tvalid_0's l2: 0.0348523\n",
      "[102]\tvalid_0's l1: 0.125609\tvalid_0's l2: 0.0348521\n",
      "[103]\tvalid_0's l1: 0.125612\tvalid_0's l2: 0.0348511\n",
      "[104]\tvalid_0's l1: 0.125615\tvalid_0's l2: 0.0348507\n",
      "[105]\tvalid_0's l1: 0.125622\tvalid_0's l2: 0.0348523\n",
      "[106]\tvalid_0's l1: 0.125633\tvalid_0's l2: 0.0348551\n",
      "[107]\tvalid_0's l1: 0.12564\tvalid_0's l2: 0.0348595\n",
      "[108]\tvalid_0's l1: 0.125647\tvalid_0's l2: 0.0348593\n",
      "[109]\tvalid_0's l1: 0.125657\tvalid_0's l2: 0.0348623\n",
      "[110]\tvalid_0's l1: 0.125669\tvalid_0's l2: 0.0348656\n",
      "[111]\tvalid_0's l1: 0.125675\tvalid_0's l2: 0.0348696\n",
      "[112]\tvalid_0's l1: 0.125676\tvalid_0's l2: 0.0348715\n",
      "[113]\tvalid_0's l1: 0.125675\tvalid_0's l2: 0.0348694\n",
      "[114]\tvalid_0's l1: 0.125672\tvalid_0's l2: 0.034871\n",
      "[115]\tvalid_0's l1: 0.125668\tvalid_0's l2: 0.0348695\n",
      "[116]\tvalid_0's l1: 0.125676\tvalid_0's l2: 0.0348726\n",
      "[117]\tvalid_0's l1: 0.125677\tvalid_0's l2: 0.0348739\n",
      "[118]\tvalid_0's l1: 0.125677\tvalid_0's l2: 0.0348756\n",
      "[119]\tvalid_0's l1: 0.125669\tvalid_0's l2: 0.0348735\n",
      "[120]\tvalid_0's l1: 0.125666\tvalid_0's l2: 0.0348744\n",
      "[121]\tvalid_0's l1: 0.12565\tvalid_0's l2: 0.0348695\n",
      "[122]\tvalid_0's l1: 0.125642\tvalid_0's l2: 0.0348679\n",
      "[123]\tvalid_0's l1: 0.125636\tvalid_0's l2: 0.0348657\n",
      "[124]\tvalid_0's l1: 0.125619\tvalid_0's l2: 0.03486\n",
      "[125]\tvalid_0's l1: 0.125618\tvalid_0's l2: 0.034858\n",
      "[126]\tvalid_0's l1: 0.125633\tvalid_0's l2: 0.0348646\n",
      "[127]\tvalid_0's l1: 0.125644\tvalid_0's l2: 0.0348688\n",
      "[128]\tvalid_0's l1: 0.125631\tvalid_0's l2: 0.0348635\n",
      "[129]\tvalid_0's l1: 0.125627\tvalid_0's l2: 0.0348601\n",
      "[130]\tvalid_0's l1: 0.125618\tvalid_0's l2: 0.0348577\n",
      "[131]\tvalid_0's l1: 0.12562\tvalid_0's l2: 0.0348522\n",
      "[132]\tvalid_0's l1: 0.12562\tvalid_0's l2: 0.0348472\n",
      "[133]\tvalid_0's l1: 0.125625\tvalid_0's l2: 0.0348433\n",
      "[134]\tvalid_0's l1: 0.125626\tvalid_0's l2: 0.0348391\n",
      "[135]\tvalid_0's l1: 0.125632\tvalid_0's l2: 0.0348369\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's l1: 0.125334\tvalid_0's l2: 0.0347967\n",
      "81.34611878241284\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( X_train, Y_train, test_size=0.2, random_state=42)\n",
    "import lightgbm as lgb\n",
    "hyper_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'l2',\n",
    "    'learning_rate': 0.005,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 10,\n",
    "    'verbose': 0,\n",
    "    \"max_depth\": 8,\n",
    "    \"num_leaves\": 80, \n",
    "    \"max_bin\": 512,\n",
    "    \"num_iterations\": 600,\n",
    "    \"n_estimators\": 1000\n",
    "}\n",
    "\n",
    "gbm = lgb.LGBMRegressor(**hyper_params)\n",
    "\n",
    "gbm.fit(x_train, y_train,\n",
    "        eval_set=[(x_test, y_test)],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=100)\n",
    "y_pr = gbm.predict(x_test)\n",
    "print(100*max(0,1-np.sqrt(mean_squared_error(y_test,y_pr))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylight = gbm.predict(X_test)\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = ylight\n",
    "sub.to_csv('light_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy = 81.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from ml_modules.custom_estimator import Estimator\n",
    "from ml_modules.custom_fold_generator import FoldScheme\n",
    "\n",
    "est = Estimator(model=CatBoostRegressor(eval_metric='RMSE', n_estimators=20000, od_type='Iter', \n",
    "                    od_wait=200, colsample_bylevel=0.7, max_depth=6, learning_rate=0.1),\n",
    "              early_stopping_rounds=200, random_state=50, validation_scheme=FoldScheme.KFold,\n",
    "              eval_metric='rmse', task_type='regression', scoring_metric=rmse, n_splits=5,\n",
    "              categorical_features_indices=cat_indices)\n",
    "\n",
    "train_preds = est.fit_transform(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = CatBoostRegressor(n_estimators = 20000,loss_function = 'RMSE',\n",
    "                    eval_metric = 'RMSE',od_type='Iter', od_wait=200, colsample_bylevel=0.7, \n",
    "                          max_depth=6, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1853018\ttest: 0.1865798\tbest: 0.1865798 (0)\ttotal: 3.25ms\tremaining: 1m 5s\n",
      "1:\tlearn: 0.1851527\ttest: 0.1865115\tbest: 0.1865115 (1)\ttotal: 6.92ms\tremaining: 1m 9s\n",
      "2:\tlearn: 0.1849283\ttest: 0.1864992\tbest: 0.1864992 (2)\ttotal: 10.5ms\tremaining: 1m 10s\n",
      "3:\tlearn: 0.1846529\ttest: 0.1865960\tbest: 0.1864992 (2)\ttotal: 14.2ms\tremaining: 1m 10s\n",
      "4:\tlearn: 0.1844555\ttest: 0.1865584\tbest: 0.1864992 (2)\ttotal: 17.7ms\tremaining: 1m 10s\n",
      "5:\tlearn: 0.1842959\ttest: 0.1865597\tbest: 0.1864992 (2)\ttotal: 21.2ms\tremaining: 1m 10s\n",
      "6:\tlearn: 0.1839314\ttest: 0.1865902\tbest: 0.1864992 (2)\ttotal: 25.6ms\tremaining: 1m 13s\n",
      "7:\tlearn: 0.1837677\ttest: 0.1865948\tbest: 0.1864992 (2)\ttotal: 29.2ms\tremaining: 1m 12s\n",
      "8:\tlearn: 0.1835603\ttest: 0.1865948\tbest: 0.1864992 (2)\ttotal: 32.5ms\tremaining: 1m 12s\n",
      "9:\tlearn: 0.1832971\ttest: 0.1866367\tbest: 0.1864992 (2)\ttotal: 36ms\tremaining: 1m 12s\n",
      "10:\tlearn: 0.1831170\ttest: 0.1866253\tbest: 0.1864992 (2)\ttotal: 39.7ms\tremaining: 1m 12s\n",
      "11:\tlearn: 0.1829644\ttest: 0.1866012\tbest: 0.1864992 (2)\ttotal: 42.9ms\tremaining: 1m 11s\n",
      "12:\tlearn: 0.1827283\ttest: 0.1865672\tbest: 0.1864992 (2)\ttotal: 46.5ms\tremaining: 1m 11s\n",
      "13:\tlearn: 0.1825620\ttest: 0.1865881\tbest: 0.1864992 (2)\ttotal: 49.8ms\tremaining: 1m 11s\n",
      "14:\tlearn: 0.1823339\ttest: 0.1866028\tbest: 0.1864992 (2)\ttotal: 53.4ms\tremaining: 1m 11s\n",
      "15:\tlearn: 0.1822003\ttest: 0.1865855\tbest: 0.1864992 (2)\ttotal: 56.9ms\tremaining: 1m 11s\n",
      "16:\tlearn: 0.1819365\ttest: 0.1866501\tbest: 0.1864992 (2)\ttotal: 60.2ms\tremaining: 1m 10s\n",
      "17:\tlearn: 0.1817790\ttest: 0.1865700\tbest: 0.1864992 (2)\ttotal: 63.8ms\tremaining: 1m 10s\n",
      "18:\tlearn: 0.1816494\ttest: 0.1865748\tbest: 0.1864992 (2)\ttotal: 67.3ms\tremaining: 1m 10s\n",
      "19:\tlearn: 0.1814895\ttest: 0.1865914\tbest: 0.1864992 (2)\ttotal: 70.6ms\tremaining: 1m 10s\n",
      "20:\tlearn: 0.1813087\ttest: 0.1866835\tbest: 0.1864992 (2)\ttotal: 73.9ms\tremaining: 1m 10s\n",
      "21:\tlearn: 0.1810392\ttest: 0.1866590\tbest: 0.1864992 (2)\ttotal: 77.5ms\tremaining: 1m 10s\n",
      "22:\tlearn: 0.1809025\ttest: 0.1866659\tbest: 0.1864992 (2)\ttotal: 81ms\tremaining: 1m 10s\n",
      "23:\tlearn: 0.1807286\ttest: 0.1866292\tbest: 0.1864992 (2)\ttotal: 84.6ms\tremaining: 1m 10s\n",
      "24:\tlearn: 0.1805422\ttest: 0.1866694\tbest: 0.1864992 (2)\ttotal: 88ms\tremaining: 1m 10s\n",
      "25:\tlearn: 0.1803742\ttest: 0.1866905\tbest: 0.1864992 (2)\ttotal: 91.2ms\tremaining: 1m 10s\n",
      "26:\tlearn: 0.1802351\ttest: 0.1866886\tbest: 0.1864992 (2)\ttotal: 94.6ms\tremaining: 1m 9s\n",
      "27:\tlearn: 0.1800817\ttest: 0.1866240\tbest: 0.1864992 (2)\ttotal: 97.9ms\tremaining: 1m 9s\n",
      "28:\tlearn: 0.1798621\ttest: 0.1866454\tbest: 0.1864992 (2)\ttotal: 101ms\tremaining: 1m 9s\n",
      "29:\tlearn: 0.1797333\ttest: 0.1867227\tbest: 0.1864992 (2)\ttotal: 104ms\tremaining: 1m 9s\n",
      "30:\tlearn: 0.1795947\ttest: 0.1867103\tbest: 0.1864992 (2)\ttotal: 107ms\tremaining: 1m 9s\n",
      "31:\tlearn: 0.1793556\ttest: 0.1867313\tbest: 0.1864992 (2)\ttotal: 110ms\tremaining: 1m 8s\n",
      "32:\tlearn: 0.1791854\ttest: 0.1867600\tbest: 0.1864992 (2)\ttotal: 114ms\tremaining: 1m 8s\n",
      "33:\tlearn: 0.1790815\ttest: 0.1867962\tbest: 0.1864992 (2)\ttotal: 117ms\tremaining: 1m 8s\n",
      "34:\tlearn: 0.1789722\ttest: 0.1868434\tbest: 0.1864992 (2)\ttotal: 120ms\tremaining: 1m 8s\n",
      "35:\tlearn: 0.1787609\ttest: 0.1868153\tbest: 0.1864992 (2)\ttotal: 123ms\tremaining: 1m 8s\n",
      "36:\tlearn: 0.1785708\ttest: 0.1867981\tbest: 0.1864992 (2)\ttotal: 127ms\tremaining: 1m 8s\n",
      "37:\tlearn: 0.1783428\ttest: 0.1868249\tbest: 0.1864992 (2)\ttotal: 130ms\tremaining: 1m 8s\n",
      "38:\tlearn: 0.1781651\ttest: 0.1868376\tbest: 0.1864992 (2)\ttotal: 133ms\tremaining: 1m 8s\n",
      "39:\tlearn: 0.1779822\ttest: 0.1868485\tbest: 0.1864992 (2)\ttotal: 136ms\tremaining: 1m 8s\n",
      "40:\tlearn: 0.1777482\ttest: 0.1868330\tbest: 0.1864992 (2)\ttotal: 140ms\tremaining: 1m 8s\n",
      "41:\tlearn: 0.1775645\ttest: 0.1868338\tbest: 0.1864992 (2)\ttotal: 143ms\tremaining: 1m 7s\n",
      "42:\tlearn: 0.1773867\ttest: 0.1868344\tbest: 0.1864992 (2)\ttotal: 146ms\tremaining: 1m 7s\n",
      "43:\tlearn: 0.1771572\ttest: 0.1868078\tbest: 0.1864992 (2)\ttotal: 150ms\tremaining: 1m 7s\n",
      "44:\tlearn: 0.1770730\ttest: 0.1868232\tbest: 0.1864992 (2)\ttotal: 153ms\tremaining: 1m 7s\n",
      "45:\tlearn: 0.1768745\ttest: 0.1867221\tbest: 0.1864992 (2)\ttotal: 156ms\tremaining: 1m 7s\n",
      "46:\tlearn: 0.1767171\ttest: 0.1866904\tbest: 0.1864992 (2)\ttotal: 160ms\tremaining: 1m 7s\n",
      "47:\tlearn: 0.1766065\ttest: 0.1867114\tbest: 0.1864992 (2)\ttotal: 163ms\tremaining: 1m 7s\n",
      "48:\tlearn: 0.1764201\ttest: 0.1867345\tbest: 0.1864992 (2)\ttotal: 166ms\tremaining: 1m 7s\n",
      "49:\tlearn: 0.1762899\ttest: 0.1867696\tbest: 0.1864992 (2)\ttotal: 171ms\tremaining: 1m 8s\n",
      "50:\tlearn: 0.1761033\ttest: 0.1866850\tbest: 0.1864992 (2)\ttotal: 177ms\tremaining: 1m 9s\n",
      "51:\tlearn: 0.1760140\ttest: 0.1867192\tbest: 0.1864992 (2)\ttotal: 182ms\tremaining: 1m 9s\n",
      "52:\tlearn: 0.1757898\ttest: 0.1866865\tbest: 0.1864992 (2)\ttotal: 186ms\tremaining: 1m 10s\n",
      "53:\tlearn: 0.1755867\ttest: 0.1866866\tbest: 0.1864992 (2)\ttotal: 190ms\tremaining: 1m 10s\n",
      "54:\tlearn: 0.1754492\ttest: 0.1866968\tbest: 0.1864992 (2)\ttotal: 195ms\tremaining: 1m 10s\n",
      "55:\tlearn: 0.1752788\ttest: 0.1867776\tbest: 0.1864992 (2)\ttotal: 200ms\tremaining: 1m 11s\n",
      "56:\tlearn: 0.1750700\ttest: 0.1867968\tbest: 0.1864992 (2)\ttotal: 207ms\tremaining: 1m 12s\n",
      "57:\tlearn: 0.1749107\ttest: 0.1868188\tbest: 0.1864992 (2)\ttotal: 244ms\tremaining: 1m 24s\n",
      "58:\tlearn: 0.1747111\ttest: 0.1868703\tbest: 0.1864992 (2)\ttotal: 277ms\tremaining: 1m 33s\n",
      "59:\tlearn: 0.1745887\ttest: 0.1869173\tbest: 0.1864992 (2)\ttotal: 282ms\tremaining: 1m 33s\n",
      "60:\tlearn: 0.1744886\ttest: 0.1868873\tbest: 0.1864992 (2)\ttotal: 286ms\tremaining: 1m 33s\n",
      "61:\tlearn: 0.1743111\ttest: 0.1868957\tbest: 0.1864992 (2)\ttotal: 291ms\tremaining: 1m 33s\n",
      "62:\tlearn: 0.1740887\ttest: 0.1868726\tbest: 0.1864992 (2)\ttotal: 297ms\tremaining: 1m 33s\n",
      "63:\tlearn: 0.1739659\ttest: 0.1869084\tbest: 0.1864992 (2)\ttotal: 300ms\tremaining: 1m 33s\n",
      "64:\tlearn: 0.1737410\ttest: 0.1870389\tbest: 0.1864992 (2)\ttotal: 303ms\tremaining: 1m 33s\n",
      "65:\tlearn: 0.1735985\ttest: 0.1870038\tbest: 0.1864992 (2)\ttotal: 307ms\tremaining: 1m 32s\n",
      "66:\tlearn: 0.1734971\ttest: 0.1869875\tbest: 0.1864992 (2)\ttotal: 310ms\tremaining: 1m 32s\n",
      "67:\tlearn: 0.1732621\ttest: 0.1870121\tbest: 0.1864992 (2)\ttotal: 313ms\tremaining: 1m 31s\n",
      "68:\tlearn: 0.1730820\ttest: 0.1870076\tbest: 0.1864992 (2)\ttotal: 316ms\tremaining: 1m 31s\n",
      "69:\tlearn: 0.1729788\ttest: 0.1870572\tbest: 0.1864992 (2)\ttotal: 320ms\tremaining: 1m 30s\n",
      "70:\tlearn: 0.1728068\ttest: 0.1870894\tbest: 0.1864992 (2)\ttotal: 323ms\tremaining: 1m 30s\n",
      "71:\tlearn: 0.1726620\ttest: 0.1871061\tbest: 0.1864992 (2)\ttotal: 326ms\tremaining: 1m 30s\n",
      "72:\tlearn: 0.1724658\ttest: 0.1871812\tbest: 0.1864992 (2)\ttotal: 329ms\tremaining: 1m 29s\n",
      "73:\tlearn: 0.1723270\ttest: 0.1872425\tbest: 0.1864992 (2)\ttotal: 333ms\tremaining: 1m 29s\n",
      "74:\tlearn: 0.1721357\ttest: 0.1872534\tbest: 0.1864992 (2)\ttotal: 336ms\tremaining: 1m 29s\n",
      "75:\tlearn: 0.1719701\ttest: 0.1873247\tbest: 0.1864992 (2)\ttotal: 340ms\tremaining: 1m 29s\n",
      "76:\tlearn: 0.1717512\ttest: 0.1873985\tbest: 0.1864992 (2)\ttotal: 344ms\tremaining: 1m 29s\n",
      "77:\tlearn: 0.1715556\ttest: 0.1875402\tbest: 0.1864992 (2)\ttotal: 352ms\tremaining: 1m 29s\n",
      "78:\tlearn: 0.1714099\ttest: 0.1875286\tbest: 0.1864992 (2)\ttotal: 356ms\tremaining: 1m 29s\n",
      "79:\tlearn: 0.1712262\ttest: 0.1875378\tbest: 0.1864992 (2)\ttotal: 361ms\tremaining: 1m 29s\n",
      "80:\tlearn: 0.1711231\ttest: 0.1875180\tbest: 0.1864992 (2)\ttotal: 365ms\tremaining: 1m 29s\n",
      "81:\tlearn: 0.1709238\ttest: 0.1875216\tbest: 0.1864992 (2)\ttotal: 369ms\tremaining: 1m 29s\n",
      "82:\tlearn: 0.1707515\ttest: 0.1874698\tbest: 0.1864992 (2)\ttotal: 373ms\tremaining: 1m 29s\n",
      "83:\tlearn: 0.1705683\ttest: 0.1874619\tbest: 0.1864992 (2)\ttotal: 377ms\tremaining: 1m 29s\n",
      "84:\tlearn: 0.1704927\ttest: 0.1874672\tbest: 0.1864992 (2)\ttotal: 382ms\tremaining: 1m 29s\n",
      "85:\tlearn: 0.1704007\ttest: 0.1875409\tbest: 0.1864992 (2)\ttotal: 386ms\tremaining: 1m 29s\n",
      "86:\tlearn: 0.1702589\ttest: 0.1875747\tbest: 0.1864992 (2)\ttotal: 391ms\tremaining: 1m 29s\n",
      "87:\tlearn: 0.1700579\ttest: 0.1875801\tbest: 0.1864992 (2)\ttotal: 396ms\tremaining: 1m 29s\n",
      "88:\tlearn: 0.1698828\ttest: 0.1876613\tbest: 0.1864992 (2)\ttotal: 399ms\tremaining: 1m 29s\n",
      "89:\tlearn: 0.1697560\ttest: 0.1876044\tbest: 0.1864992 (2)\ttotal: 404ms\tremaining: 1m 29s\n",
      "90:\tlearn: 0.1696537\ttest: 0.1876136\tbest: 0.1864992 (2)\ttotal: 408ms\tremaining: 1m 29s\n",
      "91:\tlearn: 0.1694934\ttest: 0.1876475\tbest: 0.1864992 (2)\ttotal: 415ms\tremaining: 1m 29s\n",
      "92:\tlearn: 0.1693506\ttest: 0.1876371\tbest: 0.1864992 (2)\ttotal: 423ms\tremaining: 1m 30s\n",
      "93:\tlearn: 0.1692103\ttest: 0.1876792\tbest: 0.1864992 (2)\ttotal: 428ms\tremaining: 1m 30s\n",
      "94:\tlearn: 0.1689874\ttest: 0.1877420\tbest: 0.1864992 (2)\ttotal: 432ms\tremaining: 1m 30s\n",
      "95:\tlearn: 0.1688874\ttest: 0.1877435\tbest: 0.1864992 (2)\ttotal: 436ms\tremaining: 1m 30s\n",
      "96:\tlearn: 0.1687350\ttest: 0.1877638\tbest: 0.1864992 (2)\ttotal: 443ms\tremaining: 1m 30s\n",
      "97:\tlearn: 0.1686623\ttest: 0.1877646\tbest: 0.1864992 (2)\ttotal: 446ms\tremaining: 1m 30s\n",
      "98:\tlearn: 0.1684292\ttest: 0.1877853\tbest: 0.1864992 (2)\ttotal: 451ms\tremaining: 1m 30s\n",
      "99:\tlearn: 0.1682271\ttest: 0.1877247\tbest: 0.1864992 (2)\ttotal: 455ms\tremaining: 1m 30s\n",
      "100:\tlearn: 0.1680692\ttest: 0.1877016\tbest: 0.1864992 (2)\ttotal: 460ms\tremaining: 1m 30s\n",
      "101:\tlearn: 0.1679051\ttest: 0.1877209\tbest: 0.1864992 (2)\ttotal: 467ms\tremaining: 1m 31s\n",
      "102:\tlearn: 0.1678120\ttest: 0.1877673\tbest: 0.1864992 (2)\ttotal: 473ms\tremaining: 1m 31s\n",
      "103:\tlearn: 0.1676388\ttest: 0.1877786\tbest: 0.1864992 (2)\ttotal: 478ms\tremaining: 1m 31s\n",
      "104:\tlearn: 0.1674844\ttest: 0.1878213\tbest: 0.1864992 (2)\ttotal: 482ms\tremaining: 1m 31s\n",
      "105:\tlearn: 0.1673495\ttest: 0.1879597\tbest: 0.1864992 (2)\ttotal: 486ms\tremaining: 1m 31s\n",
      "106:\tlearn: 0.1671857\ttest: 0.1879241\tbest: 0.1864992 (2)\ttotal: 490ms\tremaining: 1m 31s\n",
      "107:\tlearn: 0.1670387\ttest: 0.1879464\tbest: 0.1864992 (2)\ttotal: 493ms\tremaining: 1m 30s\n",
      "108:\tlearn: 0.1669202\ttest: 0.1879196\tbest: 0.1864992 (2)\ttotal: 500ms\tremaining: 1m 31s\n",
      "109:\tlearn: 0.1667694\ttest: 0.1879154\tbest: 0.1864992 (2)\ttotal: 511ms\tremaining: 1m 32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110:\tlearn: 0.1666882\ttest: 0.1879629\tbest: 0.1864992 (2)\ttotal: 520ms\tremaining: 1m 33s\n",
      "111:\tlearn: 0.1665043\ttest: 0.1880088\tbest: 0.1864992 (2)\ttotal: 525ms\tremaining: 1m 33s\n",
      "112:\tlearn: 0.1663423\ttest: 0.1880023\tbest: 0.1864992 (2)\ttotal: 529ms\tremaining: 1m 33s\n",
      "113:\tlearn: 0.1661866\ttest: 0.1879974\tbest: 0.1864992 (2)\ttotal: 535ms\tremaining: 1m 33s\n",
      "114:\tlearn: 0.1660630\ttest: 0.1880350\tbest: 0.1864992 (2)\ttotal: 538ms\tremaining: 1m 33s\n",
      "115:\tlearn: 0.1659502\ttest: 0.1880109\tbest: 0.1864992 (2)\ttotal: 544ms\tremaining: 1m 33s\n",
      "116:\tlearn: 0.1659197\ttest: 0.1880031\tbest: 0.1864992 (2)\ttotal: 550ms\tremaining: 1m 33s\n",
      "117:\tlearn: 0.1657993\ttest: 0.1880454\tbest: 0.1864992 (2)\ttotal: 553ms\tremaining: 1m 33s\n",
      "118:\tlearn: 0.1657430\ttest: 0.1880440\tbest: 0.1864992 (2)\ttotal: 557ms\tremaining: 1m 33s\n",
      "119:\tlearn: 0.1656204\ttest: 0.1880872\tbest: 0.1864992 (2)\ttotal: 563ms\tremaining: 1m 33s\n",
      "120:\tlearn: 0.1655358\ttest: 0.1881069\tbest: 0.1864992 (2)\ttotal: 567ms\tremaining: 1m 33s\n",
      "121:\tlearn: 0.1654602\ttest: 0.1880797\tbest: 0.1864992 (2)\ttotal: 571ms\tremaining: 1m 33s\n",
      "122:\tlearn: 0.1653195\ttest: 0.1880484\tbest: 0.1864992 (2)\ttotal: 576ms\tremaining: 1m 33s\n",
      "123:\tlearn: 0.1652290\ttest: 0.1880335\tbest: 0.1864992 (2)\ttotal: 580ms\tremaining: 1m 33s\n",
      "124:\tlearn: 0.1650894\ttest: 0.1881205\tbest: 0.1864992 (2)\ttotal: 590ms\tremaining: 1m 33s\n",
      "125:\tlearn: 0.1650235\ttest: 0.1881112\tbest: 0.1864992 (2)\ttotal: 594ms\tremaining: 1m 33s\n",
      "126:\tlearn: 0.1649008\ttest: 0.1881324\tbest: 0.1864992 (2)\ttotal: 598ms\tremaining: 1m 33s\n",
      "127:\tlearn: 0.1648567\ttest: 0.1881243\tbest: 0.1864992 (2)\ttotal: 602ms\tremaining: 1m 33s\n",
      "128:\tlearn: 0.1647499\ttest: 0.1881454\tbest: 0.1864992 (2)\ttotal: 606ms\tremaining: 1m 33s\n",
      "129:\tlearn: 0.1646580\ttest: 0.1881517\tbest: 0.1864992 (2)\ttotal: 611ms\tremaining: 1m 33s\n",
      "130:\tlearn: 0.1645386\ttest: 0.1881155\tbest: 0.1864992 (2)\ttotal: 615ms\tremaining: 1m 33s\n",
      "131:\tlearn: 0.1643993\ttest: 0.1881317\tbest: 0.1864992 (2)\ttotal: 623ms\tremaining: 1m 33s\n",
      "132:\tlearn: 0.1643059\ttest: 0.1881288\tbest: 0.1864992 (2)\ttotal: 626ms\tremaining: 1m 33s\n",
      "133:\tlearn: 0.1641901\ttest: 0.1881244\tbest: 0.1864992 (2)\ttotal: 630ms\tremaining: 1m 33s\n",
      "134:\tlearn: 0.1639976\ttest: 0.1880762\tbest: 0.1864992 (2)\ttotal: 633ms\tremaining: 1m 33s\n",
      "135:\tlearn: 0.1638999\ttest: 0.1881458\tbest: 0.1864992 (2)\ttotal: 636ms\tremaining: 1m 32s\n",
      "136:\tlearn: 0.1638043\ttest: 0.1881180\tbest: 0.1864992 (2)\ttotal: 640ms\tremaining: 1m 32s\n",
      "137:\tlearn: 0.1637142\ttest: 0.1881408\tbest: 0.1864992 (2)\ttotal: 643ms\tremaining: 1m 32s\n",
      "138:\tlearn: 0.1635041\ttest: 0.1881101\tbest: 0.1864992 (2)\ttotal: 646ms\tremaining: 1m 32s\n",
      "139:\tlearn: 0.1634103\ttest: 0.1880646\tbest: 0.1864992 (2)\ttotal: 650ms\tremaining: 1m 32s\n",
      "140:\tlearn: 0.1632399\ttest: 0.1880708\tbest: 0.1864992 (2)\ttotal: 653ms\tremaining: 1m 32s\n",
      "141:\tlearn: 0.1631537\ttest: 0.1880658\tbest: 0.1864992 (2)\ttotal: 657ms\tremaining: 1m 31s\n",
      "142:\tlearn: 0.1630373\ttest: 0.1880698\tbest: 0.1864992 (2)\ttotal: 660ms\tremaining: 1m 31s\n",
      "143:\tlearn: 0.1629179\ttest: 0.1880818\tbest: 0.1864992 (2)\ttotal: 663ms\tremaining: 1m 31s\n",
      "144:\tlearn: 0.1627712\ttest: 0.1881085\tbest: 0.1864992 (2)\ttotal: 667ms\tremaining: 1m 31s\n",
      "145:\tlearn: 0.1626827\ttest: 0.1881094\tbest: 0.1864992 (2)\ttotal: 670ms\tremaining: 1m 31s\n",
      "146:\tlearn: 0.1625948\ttest: 0.1881204\tbest: 0.1864992 (2)\ttotal: 673ms\tremaining: 1m 30s\n",
      "147:\tlearn: 0.1624810\ttest: 0.1881109\tbest: 0.1864992 (2)\ttotal: 676ms\tremaining: 1m 30s\n",
      "148:\tlearn: 0.1623646\ttest: 0.1881660\tbest: 0.1864992 (2)\ttotal: 679ms\tremaining: 1m 30s\n",
      "149:\tlearn: 0.1622840\ttest: 0.1881275\tbest: 0.1864992 (2)\ttotal: 686ms\tremaining: 1m 30s\n",
      "150:\tlearn: 0.1620942\ttest: 0.1881851\tbest: 0.1864992 (2)\ttotal: 692ms\tremaining: 1m 31s\n",
      "151:\tlearn: 0.1619431\ttest: 0.1882333\tbest: 0.1864992 (2)\ttotal: 697ms\tremaining: 1m 30s\n",
      "152:\tlearn: 0.1618136\ttest: 0.1882630\tbest: 0.1864992 (2)\ttotal: 704ms\tremaining: 1m 31s\n",
      "153:\tlearn: 0.1616837\ttest: 0.1882973\tbest: 0.1864992 (2)\ttotal: 708ms\tremaining: 1m 31s\n",
      "154:\tlearn: 0.1616206\ttest: 0.1883175\tbest: 0.1864992 (2)\ttotal: 711ms\tremaining: 1m 31s\n",
      "155:\tlearn: 0.1614727\ttest: 0.1882675\tbest: 0.1864992 (2)\ttotal: 714ms\tremaining: 1m 30s\n",
      "156:\tlearn: 0.1612823\ttest: 0.1882796\tbest: 0.1864992 (2)\ttotal: 717ms\tremaining: 1m 30s\n",
      "157:\tlearn: 0.1611354\ttest: 0.1882847\tbest: 0.1864992 (2)\ttotal: 721ms\tremaining: 1m 30s\n",
      "158:\tlearn: 0.1608764\ttest: 0.1883082\tbest: 0.1864992 (2)\ttotal: 724ms\tremaining: 1m 30s\n",
      "159:\tlearn: 0.1606764\ttest: 0.1883093\tbest: 0.1864992 (2)\ttotal: 727ms\tremaining: 1m 30s\n",
      "160:\tlearn: 0.1604476\ttest: 0.1882886\tbest: 0.1864992 (2)\ttotal: 730ms\tremaining: 1m 29s\n",
      "161:\tlearn: 0.1602645\ttest: 0.1882188\tbest: 0.1864992 (2)\ttotal: 734ms\tremaining: 1m 29s\n",
      "162:\tlearn: 0.1601512\ttest: 0.1882126\tbest: 0.1864992 (2)\ttotal: 737ms\tremaining: 1m 29s\n",
      "163:\tlearn: 0.1600802\ttest: 0.1881998\tbest: 0.1864992 (2)\ttotal: 740ms\tremaining: 1m 29s\n",
      "164:\tlearn: 0.1599751\ttest: 0.1882135\tbest: 0.1864992 (2)\ttotal: 743ms\tremaining: 1m 29s\n",
      "165:\tlearn: 0.1598568\ttest: 0.1882620\tbest: 0.1864992 (2)\ttotal: 747ms\tremaining: 1m 29s\n",
      "166:\tlearn: 0.1598368\ttest: 0.1882589\tbest: 0.1864992 (2)\ttotal: 750ms\tremaining: 1m 29s\n",
      "167:\tlearn: 0.1597231\ttest: 0.1882728\tbest: 0.1864992 (2)\ttotal: 753ms\tremaining: 1m 28s\n",
      "168:\tlearn: 0.1595799\ttest: 0.1882628\tbest: 0.1864992 (2)\ttotal: 756ms\tremaining: 1m 28s\n",
      "169:\tlearn: 0.1594625\ttest: 0.1882678\tbest: 0.1864992 (2)\ttotal: 759ms\tremaining: 1m 28s\n",
      "170:\tlearn: 0.1592374\ttest: 0.1882798\tbest: 0.1864992 (2)\ttotal: 763ms\tremaining: 1m 28s\n",
      "171:\tlearn: 0.1590703\ttest: 0.1882948\tbest: 0.1864992 (2)\ttotal: 766ms\tremaining: 1m 28s\n",
      "172:\tlearn: 0.1589572\ttest: 0.1882800\tbest: 0.1864992 (2)\ttotal: 769ms\tremaining: 1m 28s\n",
      "173:\tlearn: 0.1589354\ttest: 0.1882694\tbest: 0.1864992 (2)\ttotal: 772ms\tremaining: 1m 27s\n",
      "174:\tlearn: 0.1588109\ttest: 0.1883089\tbest: 0.1864992 (2)\ttotal: 775ms\tremaining: 1m 27s\n",
      "175:\tlearn: 0.1586058\ttest: 0.1883028\tbest: 0.1864992 (2)\ttotal: 779ms\tremaining: 1m 27s\n",
      "176:\tlearn: 0.1584688\ttest: 0.1883624\tbest: 0.1864992 (2)\ttotal: 782ms\tremaining: 1m 27s\n",
      "177:\tlearn: 0.1582763\ttest: 0.1883498\tbest: 0.1864992 (2)\ttotal: 785ms\tremaining: 1m 27s\n",
      "178:\tlearn: 0.1580770\ttest: 0.1883495\tbest: 0.1864992 (2)\ttotal: 789ms\tremaining: 1m 27s\n",
      "179:\tlearn: 0.1579337\ttest: 0.1882466\tbest: 0.1864992 (2)\ttotal: 792ms\tremaining: 1m 27s\n",
      "180:\tlearn: 0.1577915\ttest: 0.1882734\tbest: 0.1864992 (2)\ttotal: 795ms\tremaining: 1m 27s\n",
      "181:\tlearn: 0.1576725\ttest: 0.1882954\tbest: 0.1864992 (2)\ttotal: 799ms\tremaining: 1m 26s\n",
      "182:\tlearn: 0.1576052\ttest: 0.1883095\tbest: 0.1864992 (2)\ttotal: 801ms\tremaining: 1m 26s\n",
      "183:\tlearn: 0.1574630\ttest: 0.1883290\tbest: 0.1864992 (2)\ttotal: 805ms\tremaining: 1m 26s\n",
      "184:\tlearn: 0.1573113\ttest: 0.1883553\tbest: 0.1864992 (2)\ttotal: 809ms\tremaining: 1m 26s\n",
      "185:\tlearn: 0.1571673\ttest: 0.1883796\tbest: 0.1864992 (2)\ttotal: 813ms\tremaining: 1m 26s\n",
      "186:\tlearn: 0.1571077\ttest: 0.1883956\tbest: 0.1864992 (2)\ttotal: 816ms\tremaining: 1m 26s\n",
      "187:\tlearn: 0.1569536\ttest: 0.1883703\tbest: 0.1864992 (2)\ttotal: 819ms\tremaining: 1m 26s\n",
      "188:\tlearn: 0.1567462\ttest: 0.1884475\tbest: 0.1864992 (2)\ttotal: 822ms\tremaining: 1m 26s\n",
      "189:\tlearn: 0.1566091\ttest: 0.1884960\tbest: 0.1864992 (2)\ttotal: 826ms\tremaining: 1m 26s\n",
      "190:\tlearn: 0.1564542\ttest: 0.1884932\tbest: 0.1864992 (2)\ttotal: 829ms\tremaining: 1m 25s\n",
      "191:\tlearn: 0.1563652\ttest: 0.1885294\tbest: 0.1864992 (2)\ttotal: 832ms\tremaining: 1m 25s\n",
      "192:\tlearn: 0.1561974\ttest: 0.1885644\tbest: 0.1864992 (2)\ttotal: 836ms\tremaining: 1m 25s\n",
      "193:\tlearn: 0.1561145\ttest: 0.1885847\tbest: 0.1864992 (2)\ttotal: 840ms\tremaining: 1m 25s\n",
      "194:\tlearn: 0.1560146\ttest: 0.1886375\tbest: 0.1864992 (2)\ttotal: 844ms\tremaining: 1m 25s\n",
      "195:\tlearn: 0.1558708\ttest: 0.1885580\tbest: 0.1864992 (2)\ttotal: 851ms\tremaining: 1m 25s\n",
      "196:\tlearn: 0.1558430\ttest: 0.1885332\tbest: 0.1864992 (2)\ttotal: 855ms\tremaining: 1m 25s\n",
      "197:\tlearn: 0.1557497\ttest: 0.1885752\tbest: 0.1864992 (2)\ttotal: 863ms\tremaining: 1m 26s\n",
      "198:\tlearn: 0.1556587\ttest: 0.1886046\tbest: 0.1864992 (2)\ttotal: 870ms\tremaining: 1m 26s\n",
      "199:\tlearn: 0.1555295\ttest: 0.1886342\tbest: 0.1864992 (2)\ttotal: 874ms\tremaining: 1m 26s\n",
      "200:\tlearn: 0.1554996\ttest: 0.1886543\tbest: 0.1864992 (2)\ttotal: 877ms\tremaining: 1m 26s\n",
      "201:\tlearn: 0.1554042\ttest: 0.1886632\tbest: 0.1864992 (2)\ttotal: 880ms\tremaining: 1m 26s\n",
      "202:\tlearn: 0.1552236\ttest: 0.1887050\tbest: 0.1864992 (2)\ttotal: 884ms\tremaining: 1m 26s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.1864992453\n",
      "bestIteration = 2\n",
      "\n",
      "Shrink model to first 3 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x278f8e82b70>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "cat.fit(x_train,y_train,use_best_model=True,eval_set=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycat = cat.predict(X_test)\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = ycat\n",
    "sub.to_csv('cat_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = ylight*0.6 +ycat*0.2 +yxgbreg*0.2\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = ens\n",
    "sub.to_csv('ensemble_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBRFRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'XGBRFRegressor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-b4b86d6024a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBRFRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mregressor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXGBRFRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'XGBRFRegressor'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRFRegressor\n",
    "regressor=XGBRFRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=60,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)\n",
    "random_cv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ridge=Ridge()\n",
    "parameters={'alpha':[1e-10,1e-8,1e-3,1,5,10,20,30,45,55,100,110,120,130,150,1000,2000,4000,6000,7000,8000,9000]}\n",
    "ridge_regressor=GridSearchCV(ridge,parameters,scoring='neg_mean_squared_error',cv=10)\n",
    "ridge_regressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 8000}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regressor.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "yridge = ridge_regressor.predict(X_test)\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = yridge\n",
    "sub.to_csv('ridge_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy = 81.28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lasso=Lasso()\n",
    "parameters={'alpha':[1e-10,1e-8,1e-4,1e-3,1e-2,1,5,10,20,30,35,40,55,100]}\n",
    "lasso_regressor=GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=12)\n",
    "\n",
    "lasso_regressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_regressor.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylasso = lasso_regressor.predict(X_test)\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = ylasso\n",
    "sub.to_csv('lasso_submission.csv',index=False)\n",
    "\n",
    "#accu = 81.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.23536916662368, tolerance: 0.019589481083785536\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.13042393452761, tolerance: 0.019632686899999998\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.38007666761567, tolerance: 0.019246960757474285\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.50424971300926, tolerance: 0.019496539782949816\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.4291270178207, tolerance: 0.01862676156024\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.23536916662366, tolerance: 0.019589481083785536\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.13042393452757, tolerance: 0.019632686899999998\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.38007666761563, tolerance: 0.019246960757474285\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.50424971300927, tolerance: 0.019496539782949816\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.42912701782072, tolerance: 0.01862676156024\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.23536916662371, tolerance: 0.019589481083785536\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.13042393452763, tolerance: 0.019632686899999998\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.3800766676157, tolerance: 0.019246960757474285\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.50424971300927, tolerance: 0.019496539782949816\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.42912701782059, tolerance: 0.01862676156024\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.23536916662368, tolerance: 0.019589481083785536\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.13042393452761, tolerance: 0.019632686899999998\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.38007666761567, tolerance: 0.019246960757474285\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.50424971300926, tolerance: 0.019496539782949816\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.4291270178207, tolerance: 0.01862676156024\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.23536916662366, tolerance: 0.019589481083785536\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.13042393452757, tolerance: 0.019632686899999998\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.38007666761563, tolerance: 0.019246960757474285\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.50424971300927, tolerance: 0.019496539782949816\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.42912701782072, tolerance: 0.01862676156024\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.23536916662371, tolerance: 0.019589481083785536\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.13042393452763, tolerance: 0.019632686899999998\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.3800766676157, tolerance: 0.019246960757474285\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.50424971300927, tolerance: 0.019496539782949816\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.42912701782059, tolerance: 0.01862676156024\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.23536916662368, tolerance: 0.019589481083785536\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.13042393452761, tolerance: 0.019632686899999998\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.38007666761567, tolerance: 0.019246960757474285\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.50424971300926, tolerance: 0.019496539782949816\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.4291270178207, tolerance: 0.01862676156024\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.23536916662366, tolerance: 0.019589481083785536\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.13042393452757, tolerance: 0.019632686899999998\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.38007666761563, tolerance: 0.019246960757474285\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.50424971300927, tolerance: 0.019496539782949816\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.42912701782072, tolerance: 0.01862676156024\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.23536916662371, tolerance: 0.019589481083785536\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.13042393452763, tolerance: 0.019632686899999998\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.3800766676157, tolerance: 0.019246960757474285\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.50424971300927, tolerance: 0.019496539782949816\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.42912701782059, tolerance: 0.01862676156024\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.23536916662368, tolerance: 0.019589481083785536\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.13042393452761, tolerance: 0.019632686899999998\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.38007666761567, tolerance: 0.019246960757474285\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.50424971300926, tolerance: 0.019496539782949816\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.4291270178207, tolerance: 0.01862676156024\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.23536916662366, tolerance: 0.019589481083785536\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.13042393452757, tolerance: 0.019632686899999998\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.38007666761563, tolerance: 0.019246960757474285\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.50424971300927, tolerance: 0.019496539782949816\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.42912701782072, tolerance: 0.01862676156024\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.23536916662371, tolerance: 0.019589481083785536\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 97.13042393452763, tolerance: 0.019632686899999998\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.3800766676157, tolerance: 0.019246960757474285\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.50424971300927, tolerance: 0.019496539782949816\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:514: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\DELL\\Miniconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92.42912701782059, tolerance: 0.01862676156024\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                                  l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                                  positive=False, precompute=False,\n",
       "                                  random_state=None, selection='cyclic',\n",
       "                                  tol=0.0001, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [1e-08, 0.001, 0.01, 0, 1, 2, 3, 4, 5, 10, 20,\n",
       "                                   30, 35, 40],\n",
       "                         'l1_ratio': [0.2, 0.5, 0.8, 1],\n",
       "                         'max_iter': [1000, 500, 1500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet=ElasticNet()\n",
    "parameters={'alpha':[1e-8,1e-3,1e-2,0,1,2,3,4,5,10,20,30,35,40],\n",
    "           'l1_ratio':[0.2,0.5,0.8,1],\n",
    "           'max_iter':[1000,500,1500]}\n",
    "elasticnet_regressor=GridSearchCV(enet,parameters,\n",
    "                                  scoring='neg_mean_squared_error',cv=5)\n",
    "\n",
    "elasticnet_regressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01, 'l1_ratio': 1, 'max_iter': 1000}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elasticnet_regressor.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = elasticnet_regressor.predict(X_test)\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = ypred\n",
    "sub.to_csv('elastic_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid = {'n_estimators': [100,200, 400, 600, 800, 1000, 1200, 1400,1800],\n",
    "               'max_features':['auto', 'sqrt','log2'],\n",
    "               'max_depth': [7,10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "               'min_samples_split':  [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4,10],\n",
    "               'bootstrap':[True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 19.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators='warn',\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_sta...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [7, 10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 10],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 400, 600,\n",
       "                                                         800, 1000, 1200, 1400,\n",
       "                                                         1800]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 50, cv = 3, verbose=2, \n",
    "                               random_state=42,n_jobs = -1)\n",
    "rf_random.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 10,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 7,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,\n",
       "                      max_features='sqrt', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=10, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''rf =RandomForestRegressor(n_estimators=800,\n",
    "                          min_samples_split=10,max_features='log2',\n",
    "                         min_samples_leaf=10,max_depth=7,\n",
    "                         bootstrap=True)'''\n",
    "rf = RandomForestRegressor(n_estimators=100,min_samples_leaf=10,\n",
    "                          min_samples_split=2,max_features='sqrt',\n",
    "                          max_depth=7,bootstrap=True)\n",
    "rf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrf = rf.predict(X_test)\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = yrf\n",
    "sub.to_csv('randomforest_submission.csv',index=False)\n",
    "\n",
    "\n",
    "#accuracy = 81.225\n",
    "#accuracy = 81.20658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred= rf_random.predict(X_test)\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = ypred\n",
    "sub.to_csv('randomforest_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = ylasso*0.90 +yridge*.10\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = ensemble\n",
    "sub.to_csv('ensemble_submission.csv',index=False)\n",
    "\n",
    "#accuracy = 81.2612"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 24.4min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 69.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 9min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "random_grid = {'n_estimators': [90,100,200, 400, 600, 800, 1000, 1200, 1400],\n",
    "               'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "               'max_depth': [3,7,10, 20, 30, 50, 60, 80, 90, 100, None],\n",
    "               'min_samples_split':  [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4,10],\n",
    "               'learning_rate': [0.01,0.1,0.2,0.02]\n",
    "              }\n",
    "grad = GradientBoostingRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator = grad, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 50, cv = 3, verbose=1, \n",
    "                               random_state=42,n_jobs = -1)\n",
    "rf_random.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 90,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 10,\n",
       " 'max_depth': 7,\n",
       " 'loss': 'ls',\n",
       " 'learning_rate': 0.01}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.0344           27.14s\n",
      "         2           0.0344           25.48s\n",
      "         3           0.0343           25.16s\n",
      "         4           0.0343           25.71s\n",
      "         5           0.0342           25.74s\n",
      "         6           0.0342           27.77s\n",
      "         7           0.0341           27.41s\n",
      "         8           0.0341           27.19s\n",
      "         9           0.0340           26.85s\n",
      "        10           0.0340           26.71s\n",
      "        20           0.0336           26.05s\n",
      "        30           0.0332           24.48s\n",
      "        40           0.0328           23.48s\n",
      "        50           0.0324           23.67s\n",
      "        60           0.0320           22.79s\n",
      "        70           0.0317           22.00s\n",
      "        80           0.0313           21.35s\n",
      "        90           0.0310           20.87s\n",
      "       100           0.0307           20.23s\n",
      "       200           0.0282           14.27s\n",
      "       300           0.0263            8.91s\n",
      "       400           0.0243            4.40s\n",
      "       500           0.0225            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.01, loss='ls', max_depth=7,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=10, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = GradientBoostingRegressor(n_estimators=500,min_samples_split=2,\n",
    "                                min_samples_leaf=10,max_depth=7,\n",
    "                                loss='ls',learning_rate=0.01,verbose=1)\n",
    "grad.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ygrad= grad.predict(X_test)\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = ygrad\n",
    "sub.to_csv('grad_submission.csv',index=False)\n",
    "\n",
    "#80.65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:    2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_iter': 100, 'lambda_2': 0.0001, 'lambda_1': 0.1, 'alpha_2': 0.1, 'alpha_1': 1e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    8.6s finished\n"
     ]
    }
   ],
   "source": [
    "param = { 'n_iter':[200,400,100,150,500],\n",
    "          'lambda_1':[1e-06,1e-04,1e-02,1e-01,0],\n",
    "          'alpha_1': [1e-06,1e-04,1e-02,1e-01,0],\n",
    "          'lambda_2':[1e-06,1e-04,1e-02,1e-01,0],\n",
    "          'alpha_2': [1e-06,1e-04,1e-02,1e-01,0]}\n",
    "bay = BayesianRidge()\n",
    "rf_random = RandomizedSearchCV(estimator = bay, \n",
    "                               param_distributions = param, \n",
    "                               n_iter = 100, cv = 10, verbose=0.5, \n",
    "                               random_state=42,n_jobs = -1)\n",
    "rf_random.fit(X_train,Y_train)\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after  14  iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesianRidge(alpha_1=1e-06, alpha_2=0.1, compute_score=True, copy_X=True,\n",
       "              fit_intercept=True, lambda_1=0.1, lambda_2=0.0001, n_iter=100,\n",
       "              normalize=True, tol=0.001, verbose=2)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bay = BayesianRidge(n_iter= 100, lambda_2= 1e-04, \n",
    "                    lambda_1= 0.1, alpha_2=0.1, alpha_1= 1e-6,verbose=2,normalize=True,compute_score=True)\n",
    "bay.fit(X_train,Y_train)\n",
    "\n",
    "#accuarcy default = 81.26082\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "ybay = bay.predict(X_test)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = ybay\n",
    "sub.to_csv('bay_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = ybay*0.60 +yridge*.20 + ylasso*.20\n",
    " \n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = ybay\n",
    "sub.to_csv('bay_submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "MLP = MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP.fit(X_train,Y_train)\n",
    "ymlp = MLP.predict(X_test)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['Employee_ID'] = test['Employee_ID']\n",
    "sub['Attrition_rate'] = ymlp\n",
    "sub.to_csv('mlp_submission.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, Y_train, \n",
    "                                   scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    # we define clones of the original models to fit the data in\n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    #Now we do the predictions for cloned models and average them\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=156)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after  29  iterations\n",
      "Convergence after  11  iterations\n",
      "Convergence after  16  iterations\n",
      "Convergence after  15  iterations\n",
      "Convergence after  26  iterations\n",
      " Averaged base models score: 0.1856 (0.0069)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (ridge ,bay, lasso))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([   1,    2,    3,    4,    5,    7,    8,    9,   11,   12,\\n            ...\\n            5582, 5583, 5584, 5586, 5591, 5592, 5593, 5594, 5595, 5597],\\n           dtype='int64', length=4480)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-186-ddb83f19ec02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                                  meta_model = lasso)\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrmsle_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstacked_averaged_models\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Stacking Averaged models score: {:.4f} ({:.4f})\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-181-0d9cd66b4a10>\u001b[0m in \u001b[0;36mrmsle_cv\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mkf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     rmse= np.sqrt(-cross_val_score(model, X_train, Y_train, \n\u001b[1;32m----> 9\u001b[1;33m                                    scoring=\"neg_mean_squared_error\", cv = kf))\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 231\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-183-dfca4af6e9d1>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_models_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mholdout_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mout_of_fold_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mholdout_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2804\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m         )\n\u001b[0;32m   1555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([   1,    2,    3,    4,    5,    7,    8,    9,   11,   12,\\n            ...\\n            5582, 5583, 5584, 5586, 5591, 5592, 5593, 5594, 5595, 5597],\\n           dtype='int64', length=4480)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (bay,ridge),\n",
    "                                                 meta_model = lasso)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
